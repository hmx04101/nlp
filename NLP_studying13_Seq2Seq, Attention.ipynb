{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298de081-d9e5-48aa-8014-b509e0582774",
   "metadata": {},
   "source": [
    "<h2>Sequence-to-Sequence</h2>\n",
    "<b>Sequence-to-Sequence(Seq2Seq) 는 입력된 시퀀스로부터 다른 도메인의 시퀀스를 출력하는 모델, 기계 번역 등</b><br>\n",
    "<b>RNN 기술을 조합해 만들며, Encoder와 Decoder로 구성</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de05d5c0-005e-4a61-994b-bb7430d8591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import urllib3\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b3c396-1e47-4b5a-8905-b9b485487c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "\n",
    "with http.request('GET', url, preload_content = False) as r, open(zipfilename, 'wb') as out_file:\n",
    "    shutil.copyfileobj(r, out_file)\n",
    "    \n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f19ab5-4357-44e3-a6c9-a42f4e85a5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189986"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.read_csv('fra.txt', names = ['src', 'tar', 'lic'], sep = '\\t')\n",
    "del lines['lic']\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c6da49-44c7-4ca5-b805-6b7ec72d73df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Va !\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Marche.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Bouge !\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut !\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Cours !\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Courez !\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Prenez vos jambes à vos cous !\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t File !\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Filez !\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    src                                  tar\n",
       "0   Go.                            \\t Va !\\n\n",
       "1   Go.                         \\t Marche.\\n\n",
       "2   Go.                         \\t Bouge !\\n\n",
       "3   Hi.                         \\t Salut !\\n\n",
       "4   Hi.                          \\t Salut.\\n\n",
       "5  Run!                         \\t Cours !\\n\n",
       "6  Run!                        \\t Courez !\\n\n",
       "7  Run!  \\t Prenez vos jambes à vos cous !\\n\n",
       "8  Run!                          \\t File !\\n\n",
       "9  Run!                         \\t Filez !\\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[:60000]\n",
    "lines.tar = lines.tar.apply(lambda x: '\\t ' + x + '\\n' )\n",
    "lines[:10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57231e2e-2e78-44e6-8251-8c5a5b4e7a5c",
   "metadata": {},
   "source": [
    "<b>글자 단위로 예측하기 위해 글자 집합 구축</b><br>\n",
    "<b>구축 후, 정렬해 인덱스 부여후 글자에 해당하는 사전 만듦</b><br>\n",
    "<b>글자를 모델에 투입하도록 변환하거나 예측시 반환되는 인덱스를 글자로 변환할 때 사용</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42f2c4a-dbb2-4ac2-b2a1-96f809caf671",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = set()\n",
    "for line in lines.src:\n",
    "    for char in line:\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dec7394-5478-470e-80ad-e059848f3206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "\n",
    "src_vocab_size = len(src_vocab) + 1\n",
    "tar_vocab_size = len(tar_vocab) + 1\n",
    "\n",
    "src_to_idx = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_idx = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "\n",
    "print(src_to_idx)\n",
    "print(tar_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa680a6-233a-4718-9607-249ddd62b174",
   "metadata": {},
   "source": [
    "<b>인코더에 입력될 데이터 구성, 글자 하나씩을 사전을 이용해 인덱스로 변환해 리스트에 넣음</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4d92a5-c42b-4469-a819-84f9ff567cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10], [31, 58, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines.src:\n",
    "    encoder_input.append([src_to_idx[w] for w in line])\n",
    "    \n",
    "print(encoder_input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604676b9-de3b-4ca4-9e73-b8b71f34a371",
   "metadata": {},
   "source": [
    "<b>디코더에 입력될 데이터 구성, 목표 데이터에 해당하는 사전을 사용해야 함</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0311b1bf-7c49-44e3-820d-1220731a5e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 48, 53, 3, 4, 2], [1, 3, 39, 53, 70, 55, 60, 57, 14, 2], [1, 3, 28, 67, 73, 59, 57, 3, 4, 2], [1, 3, 45, 53, 64, 73, 72, 3, 4, 2], [1, 3, 45, 53, 64, 73, 72, 14, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    decoder_input.append([tar_to_idx[w] for w in line])\n",
    "    \n",
    "print(decoder_input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646ce853-0176-4cf3-adc6-14737a9b217c",
   "metadata": {},
   "source": [
    "<b>디코더 출력과 비교할 목표 데이터 구성, 디코더와 동일하나 시작 토큰 제외</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5bbcbcc-eb43-40b8-9033-abe6851cea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 48, 53, 3, 4, 2], [3, 39, 53, 70, 55, 60, 57, 14, 2], [3, 28, 67, 73, 59, 57, 3, 4, 2], [3, 45, 53, 64, 73, 72, 3, 4, 2], [3, 45, 53, 64, 73, 72, 14, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    decoder_target.append([tar_to_idx[w] for w in line if w != '\\t'])\n",
    "    \n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12eb91ed-4e69-4c74-9cec-62cf7a83ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_src_len, padding = 'post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_tar_len, padding = 'post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_tar_len, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39365cbb-ed99-4dc2-9a8a-9a3c7225026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8301425-c375-4ca0-9db2-bb63aae97ace",
   "metadata": {},
   "source": [
    "<h2>인코더 모델 구성</h2>\n",
    "<b>Encoder 구성은 일반 LSTM 모델과 동일</b><br>\n",
    "<b>LSTM 안의 return_state는 은닉 상태를 반환해줘 seq2seq 모델을 구성할 때 필요</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e719e5-0682-4d20-8bef-c765bb048ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "475c3611-ac85-412b-8bd6-1f5c81ba71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape = (None, src_vocab_size))\n",
    "encoder_lstm = LSTM(256, return_state = True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde774b-90e6-47e3-ba01-892bee2b62e2",
   "metadata": {},
   "source": [
    "<h2>디코더 모델 구성</h2>\n",
    "<b>모델 구성은 Encoder와 거의 유사</b><br>\n",
    "<b>LSTM 안의 return_sequences는 출력을 시퀀스로 반환할 때 사용</b><br>\n",
    "<b>decoder_lstm 사용시 initial_state를 인코더의 은닉 상태로 설정</b><br>\n",
    "<b>마지막으로 Dense layer와 softmax를 통과해 예측 글자에 해당하는 인덱스를 반환</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e03c17d5-1d2b-4d58-9627-3df443f0d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "decoder_inputs = Input(shape = (None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(256, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation = 'softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa5dc6b-2b65-4925-afce-f971a2cf4d04",
   "metadata": {},
   "source": [
    "<h2>Seq2Seq 모델</h2>\n",
    "<b>Encoder와 Decoder를 결합해 Seq2Seq model 구성</b><br>\n",
    "<b>구성한 모델과 준비한 데이터를 사용해 기계 번역 학습</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a3bca58-7577-4f9e-9759-ff84fb89f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer = 'rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a12724-70cb-4dc6-8f26-d756737786c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 [==============================] - 320s 770ms/step - loss: 1.2242 - val_loss: 0.7898\n",
      "Epoch 2/25\n",
      "375/375 [==============================] - 271s 722ms/step - loss: 0.5864 - val_loss: 0.6556\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - 198s 529ms/step - loss: 0.4825 - val_loss: 0.5594\n",
      "Epoch 4/25\n",
      "375/375 [==============================] - 189s 503ms/step - loss: 0.4195 - val_loss: 0.5045\n",
      "Epoch 5/25\n",
      "375/375 [==============================] - 189s 505ms/step - loss: 0.3784 - val_loss: 0.4712\n",
      "Epoch 6/25\n",
      "375/375 [==============================] - 190s 507ms/step - loss: 0.3501 - val_loss: 0.4452\n",
      "Epoch 7/25\n",
      "375/375 [==============================] - 188s 500ms/step - loss: 0.3260 - val_loss: 0.4239\n",
      "Epoch 8/25\n",
      "375/375 [==============================] - 195s 521ms/step - loss: 0.3092 - val_loss: 0.4122\n",
      "Epoch 9/25\n",
      "375/375 [==============================] - 190s 507ms/step - loss: 0.2934 - val_loss: 0.4003\n",
      "Epoch 10/25\n",
      "375/375 [==============================] - 189s 504ms/step - loss: 0.2818 - val_loss: 0.3924\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - 190s 506ms/step - loss: 0.2717 - val_loss: 0.3840\n",
      "Epoch 12/25\n",
      "375/375 [==============================] - 186s 497ms/step - loss: 0.2622 - val_loss: 0.3793\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - 187s 500ms/step - loss: 0.2549 - val_loss: 0.3764\n",
      "Epoch 14/25\n",
      "375/375 [==============================] - 187s 497ms/step - loss: 0.2467 - val_loss: 0.3707\n",
      "Epoch 15/25\n",
      "375/375 [==============================] - 185s 493ms/step - loss: 0.2412 - val_loss: 0.3663\n",
      "Epoch 16/25\n",
      "375/375 [==============================] - 190s 506ms/step - loss: 0.2351 - val_loss: 0.3636\n",
      "Epoch 17/25\n",
      "375/375 [==============================] - 188s 501ms/step - loss: 0.2292 - val_loss: 0.3618\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - 186s 497ms/step - loss: 0.2243 - val_loss: 0.3612\n",
      "Epoch 19/25\n",
      "375/375 [==============================] - 189s 503ms/step - loss: 0.2197 - val_loss: 0.3601\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - 191s 509ms/step - loss: 0.2153 - val_loss: 0.3600\n",
      "Epoch 21/25\n",
      "375/375 [==============================] - 187s 497ms/step - loss: 0.2105 - val_loss: 0.3589\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - 190s 507ms/step - loss: 0.2065 - val_loss: 0.3588\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - 187s 499ms/step - loss: 0.2024 - val_loss: 0.3603\n",
      "Epoch 24/25\n",
      "375/375 [==============================] - 185s 494ms/step - loss: 0.1991 - val_loss: 0.3603\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - 187s 498ms/step - loss: 0.1965 - val_loss: 0.3610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b7a034d90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [encoder_input, decoder_input], y = decoder_target,\n",
    "         batch_size = 128,\n",
    "         epochs = 25,\n",
    "         validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ec9f8-e7a1-4d4a-85d4-8b20ac08da45",
   "metadata": {},
   "source": [
    "<h2>예측</h2>\n",
    "<b>일반 모델과 달리 seq2seq는 모델 예측 프로세스가 다름</b><br>\n",
    "<b>예측할 때는 인덱스를 하나씩 예측, 예측한 인덱스를 저장하고 다시 입력으로 사용해 종료 토큰이 나올 때까지 반복</b><br>\n",
    "<b>마지막으로 예측한 인덱스들을 사전을 통해 글자로 변환해 최종 예측을 얻음</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "219d0e21-aa6e-40d3-b629-9f4e667997a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a4160db-f8d5-4b59-902e-1042d5591390",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape = (256))\n",
    "decoder_state_input_c = Input(shape = (256))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs = [decoder_inputs] + decoder_states_inputs,\n",
    "                     outputs = [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "621a8742-a1e7-4a64-9f8d-64546f8e3afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_src = dict((i, char) for char, i in src_to_idx.items())\n",
    "idx_to_tar = dict((i, char) for char, i in tar_to_idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc773019-a00d-446d-91b5-9c0fa4193e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_decode(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_idx['\\t']] = 1\n",
    "    \n",
    "    stop = False\n",
    "    decoded_sentence = \"\"\n",
    "    \n",
    "    while not stop:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx_to_tar[sampled_token_index]\n",
    "        \n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        if sampled_char == '\\n' or len(decoded_sentence) > max_tar_len:\n",
    "            stop = True\n",
    "            \n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        \n",
    "        states_values = [h, c]\n",
    "        \n",
    "    return decoded_sentence    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e81d1f1-8ef4-440a-8556-abee54525325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70c8888c-abf5-4648-b1c4-1f6114385656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력:  Hug me.\n",
      "정답:   Serrez-moi dans vos bras !\n",
      "번역:                                                                              \n",
      "\n",
      "입력:  Come in.\n",
      "정답:   Entre.\n",
      "번역:                                                                              \n",
      "\n",
      "입력:  Hold it!\n",
      "정답:   Restez où vous êtes !\n",
      "번역:                                                                              \n",
      "\n",
      "입력:  Tom won.\n",
      "정답:   Tom a gagné.\n",
      "번역:                                                                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [100, 200, 300, 400]:\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = predict_decode(input_seq)\n",
    "    \n",
    "    print(\"입력: \", lines.src[seq_index])\n",
    "    print(\"정답: \", lines.tar[seq_index][1:len(lines.tar[seq_index]) - 1])\n",
    "    print(\"번역: \", decoded_sentence[:len(decoded_sentence) - 1], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9dc1f-0413-429c-b114-5ea52afbf016",
   "metadata": {},
   "source": [
    "<b>seq2seq 모델은 하나의 고정 길이 벡터에 모든 정보를 압축해 정보 손실 발생</b><br>\n",
    "<b>RNN의 기울기 소실 문제가 똑같이 발생</b><br>\n",
    "<b>Attention Mechanism으로 보완, 디코더가 예측하는 시점마다 인코더의 전체 입력 문장을 다시 참조</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b170bc20-8220-471c-81ba-202fa2df9128",
   "metadata": {},
   "source": [
    "<b>Encoder</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fe1d5af-870d-404b-af8a-90d8ba87c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape = (None, src_vocab_size))\n",
    "encoder_lstm = LSTM(256, return_state = True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca25e72-5f3c-413b-a651-ad19ce2999dc",
   "metadata": {},
   "source": [
    "<b>Decoder</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccf81e69-b7b0-4129-b3aa-9faa662e2196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edeeddd3-7644-4df4-be15-93fd6e946bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape = (None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(256, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "\n",
    "S_ = tf.concat([state_h[:, tf.newaxis, :], decoder_outputs[:, :-1, :]], axis = 1)\n",
    "\n",
    "attention = Attention()\n",
    "context_vector = attention([S_, encoder_outputs])\n",
    "concat = tf.concat([decoder_outputs, context_vector], axis = -1)\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation = 'softmax')\n",
    "decoder_outputs = decoder_softmax_layer(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6677e3-cb34-4c2a-8525-b72fd657211d",
   "metadata": {},
   "source": [
    "<b>Seq2Seq와 동일한 model 구성 방법</b><br>\n",
    "<b>Attention mechanism 활용 후 학습 시간이 절반 가량으로 줄어듦</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba7301af-bbf9-41f1-89a6-e78c63cbac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer = 'rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db5bc635-29c5-4c95-bb24-c9d0000d7bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 [==============================] - 335s 869ms/step - loss: 1.1627 - val_loss: 0.7853\n",
      "Epoch 2/25\n",
      "375/375 [==============================] - 350s 934ms/step - loss: 0.5819 - val_loss: 0.6455\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - 506s 1s/step - loss: 0.4781 - val_loss: 0.5712\n",
      "Epoch 4/25\n",
      "375/375 [==============================] - 445s 1s/step - loss: 0.4128 - val_loss: 0.5202\n",
      "Epoch 5/25\n",
      "375/375 [==============================] - 412s 1s/step - loss: 0.3723 - val_loss: 0.4938\n",
      "Epoch 6/25\n",
      "375/375 [==============================] - 237s 632ms/step - loss: 0.3444 - val_loss: 0.4696\n",
      "Epoch 7/25\n",
      "375/375 [==============================] - 238s 636ms/step - loss: 0.3214 - val_loss: 0.4563\n",
      "Epoch 8/25\n",
      "375/375 [==============================] - 235s 627ms/step - loss: 0.3055 - val_loss: 0.4381\n",
      "Epoch 9/25\n",
      "375/375 [==============================] - 233s 621ms/step - loss: 0.2896 - val_loss: 0.4320\n",
      "Epoch 10/25\n",
      "375/375 [==============================] - 234s 625ms/step - loss: 0.2783 - val_loss: 0.4193\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - 234s 623ms/step - loss: 0.2686 - val_loss: 0.4160\n",
      "Epoch 12/25\n",
      "375/375 [==============================] - 233s 622ms/step - loss: 0.2595 - val_loss: 0.4076\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - 236s 629ms/step - loss: 0.2520 - val_loss: 0.4040\n",
      "Epoch 14/25\n",
      "375/375 [==============================] - 234s 624ms/step - loss: 0.2433 - val_loss: 0.4006\n",
      "Epoch 15/25\n",
      "375/375 [==============================] - 233s 622ms/step - loss: 0.2372 - val_loss: 0.3956\n",
      "Epoch 16/25\n",
      "375/375 [==============================] - 236s 630ms/step - loss: 0.2325 - val_loss: 0.3940\n",
      "Epoch 17/25\n",
      "375/375 [==============================] - 235s 627ms/step - loss: 0.2266 - val_loss: 0.3912\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - 238s 636ms/step - loss: 0.2213 - val_loss: 0.3897\n",
      "Epoch 19/25\n",
      "375/375 [==============================] - 244s 651ms/step - loss: 0.2163 - val_loss: 0.3880\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - 234s 624ms/step - loss: 0.2134 - val_loss: 0.3864\n",
      "Epoch 21/25\n",
      "375/375 [==============================] - 239s 636ms/step - loss: 0.2074 - val_loss: 0.3847\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - 236s 628ms/step - loss: 0.2042 - val_loss: 0.3852\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - 238s 635ms/step - loss: 0.2000 - val_loss: 0.3883\n",
      "Epoch 24/25\n",
      "375/375 [==============================] - 234s 624ms/step - loss: 0.1970 - val_loss: 0.3857\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - 234s 625ms/step - loss: 0.1932 - val_loss: 0.3865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a18235490>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [encoder_input, decoder_input], \n",
    "          y = decoder_target,\n",
    "          batch_size = 128,\n",
    "          epochs = 25,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7dd5c-f394-4a52-806d-c80c93419729",
   "metadata": {},
   "source": [
    "<h2>예측</h2>\n",
    "<b>seq2seq과 동일하나, 추가된 모델 구조를 반영해줘야함(Attention layer)</b><br>\n",
    "<b>Encoder와 Decoder를 분리하였기에 디코더에서 은닉 상태(estate_h)와 최종 은닉 상태(encoder_outputs)를 따로 입력 받아야함</b><br>estate_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32167833-9f67-44f3-948f-3eec5c547288",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, \n",
    "                      outputs =[encoder_outputs, encoder_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0493eee8-122e-4953-9c85-1e42bd2c5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape = (256))\n",
    "decoder_state_input_c = Input(shape = (256))\n",
    "estate_h = Input(shape = (256))\n",
    "encoder_outputs = Input(shape = (256))\n",
    "\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "S_ = tf.concat([estate_h[:, tf.newaxis, :], decoder_outputs[:, :-1, :]], axis = 1)\n",
    "context_vector = attention([S_, encoder_outputs])\n",
    "decoder_concat = tf.concat([decoder_outputs, context_vector], axis = -1)\n",
    "decoder_outputs = decoder_softmax_layer(decoder_concat)\n",
    "decoder_model = Model(inputs = [decoder_inputs, estate_h, encoder_outputs] + decoder_states_inputs,\n",
    "                     outputs = [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5172e7f-6184-4b86-92b9-8ce6c2b8f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_src = dict((i, char) for char, i in src_to_idx.items())\n",
    "idx_to_tar = dict((i, char) for char, i in tar_to_idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd94aafd-f570-4745-83d9-3f48776672e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_decode(input_seq):\n",
    "    outputs_input, states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_idx['\\t']] = 1\n",
    "    \n",
    "    stop = False\n",
    "    decoded_sentence = \"\"\n",
    "    \n",
    "    while not stop:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq, states_value[0], outputs_input] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx_to_tar[sampled_token_index]\n",
    "        \n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        if sampled_char == '\\n' or len(decoded_sentence) > max_tar_len:\n",
    "            stop = True\n",
    "            \n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        \n",
    "        states_values = [h, c]\n",
    "        \n",
    "    return decoded_sentence    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90359051-6fee-48a8-bb16-3eb01fa2ed76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력:  Hug me.\n",
      "정답:   Serrez-moi dans vos bras !\n",
      "번역:                                                                              \n",
      "\n",
      "입력:  Come in.\n",
      "정답:   Entre.\n",
      "번역:                                                                              \n",
      "\n",
      "입력:  Hold it!\n",
      "정답:   Restez où vous êtes !\n",
      "번역:                                                                              \n",
      "\n",
      "입력:  Tom won.\n",
      "정답:   Tom a gagné.\n",
      "번역:                                                                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [100, 200, 300, 400]:\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = predict_decode(input_seq)\n",
    "    \n",
    "    print(\"입력: \", lines.src[seq_index])\n",
    "    print(\"정답: \", lines.tar[seq_index][1:len(lines.tar[seq_index]) - 1])\n",
    "    print(\"번역: \", decoded_sentence[:len(decoded_sentence) - 1], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
