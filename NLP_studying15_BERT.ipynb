{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2debd1-85f1-46ef-a051-4eefb2b536f1",
   "metadata": {},
   "source": [
    "<h2>BERT(Bidirectional Encoder Representations from Transformers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c43b38-ef3a-4f81-990e-49bb6f3eb8c5",
   "metadata": {},
   "source": [
    "<h2>Input representation</h2>\n",
    "<b>3가지 입력 임베딩(Token, Segment, Position)의 합으로 구성</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4333542-689f-4176-a650-e46dbcf4a2ba",
   "metadata": {},
   "source": [
    "<b>Token Embedding - Word Piece 임베딩 방식, 가장 긴 길이의 sub-word를 하나의 단위로 생성</b><br>\n",
    "<b>기존 워드 임베딩 방법에 존재하는 Out-of-vocabulary(OOV) 처리에 효과적이며 정확도 상승 효과도 있음</b><br>\n",
    "\n",
    "<b>Sentence Embeddings - 입력 길이의 제한으로 두 문장은 합쳐서 512 subword 이하로 제한</b><br>\n",
    "<b>긴 문장은 128로 제한하여 학습한 후, 나머지 입력들을 모아 마지막에 따로 추가 학습하는 방식</b><br>\n",
    "\n",
    "<b>Position Embedding - 입력 토큰 위치 정보가 필요한 Self-Attention 모델을 사용</b><br>\n",
    "<b>단순하게 Token 순서대로 0,1,2 ... 와 같이 순서대로 인코딩</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e81292-e564-4513-8552-7eec037c3c31",
   "metadata": {},
   "source": [
    "<h2>언어 모델링 데이터</h2>\n",
    "<b>총 3.3억 단어(8억 단어의 BookCorpus 데이터와 25억 단어 Wikipedia 데이터)를 이용한 학습</b><br>\n",
    "<b>MLM, NSP 모델 적용을 위해 스스로 라벨을 만들고 수행하여 준지도학습(Semi-supervised)라고 함</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b14404-1103-4709-a8b5-716be73e97e7",
   "metadata": {},
   "source": [
    "<b>MLM(Masked Language Model) - 입력 문장에서 임의로 Token을 마스킹(masking), 그 Token을 맞추는 방식, 문장 빈칸 채우기 문제 학습</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa235816-8593-4db2-be65-90d8ef399d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "badd8b58-5c17-46c3-b0fb-9d9dcfff6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(111)\n",
    "np.random.seed(111)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_LEN = 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7cf4cb-a71d-495e-9e89-8883af77c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f54a81-6768-46c8-8d04-f0ba210b9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "train_file = urllib.request.urlopen('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
    "test_file = urllib.request.urlopen('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')\n",
    "\n",
    "train_data = pd.read_table(train_file)\n",
    "test_data = pd.read_table(test_file)\n",
    "\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d05898-6299-4a25-bc88-7c0fca9f825e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767ebba4-93df-400c-a52d-1b795f43539d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847192e-03b0-46ba-9fbc-992e85b0c684",
   "metadata": {},
   "source": [
    "<b>BerTokenizer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ead280d-9d2e-49ee-8cd1-8a9e515c39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e21375d-0892-4e93-b315-b2aca41f6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110b47e9-7797-4991-8982-3e1cdb0d5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', cache_dir = 'bert_ckpt', do_lower_case = False)\n",
    "\n",
    "def bert_tokenizer(sentence, MAX_LEN):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sentence,\n",
    "        add_special_tokens = True,\n",
    "        max_length = MAX_LEN,\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True\n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a58d3e-d89b-4f75-b069-7d4edc1a69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "train_data_labels = []\n",
    "\n",
    "for train_sentence, train_label in tqdm(zip(train_data['document'], train_data['label']), total = len(train_data)):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(train_sentence, MAX_LEN)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        train_data_labels.append(train_label)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "train_movie_input_ids = np.array(input_ids , dtype = int)\n",
    "train_movie_attention_masks = np.array(attention_masks, dtype = int)\n",
    "train_movie_token_type_ids = np.array(token_type_ids, dtype = int)\n",
    "train_movie_inputs = (train_movie_input_ids, train_movie_attention_masks, train_movie_token_type_ids)\n",
    "train_data_labels = np.asarray(train_data_labels, dtype=np.int32)\n",
    "        \n",
    "    \n",
    "print(\"Sentences: {}\\nLabels: {}\".format(len(train_movie_input_ids), len(train_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90769e59-e833-46f5-b31d-788864fb7af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   101   9247   8867  32158  23811    100    124  24982  17655   9757\n",
      "  55511    122  23321  10954  24017  12030    129 106249  24974  30858\n",
      "  18227    119    100    119    119    119   9353  30134  21789  12092\n",
      "   9519 118671 119169    119    102      0      0      0      0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[CLS] 막 걸음마 [UNK] 3세부터 초등학교 1학년생인 8살용영화. [UNK]... 별반개도 아까움. [SEP] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "\n",
    "input_id = train_movie_input_ids[idx]\n",
    "attention_mask = train_movie_attention_masks[idx]\n",
    "token_type_id = train_movie_token_type_ids[idx]\n",
    "\n",
    "print(input_id)\n",
    "print(attention_mask)\n",
    "print(token_type_id)\n",
    "print(tokenizer.decode(input_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969543a4-ad50-41b5-8fcb-d0aececc40a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertClassifier, self).__init__()\n",
    "        \n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir = dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class,\n",
    "                                               kernel_initializer = tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range),\n",
    "                                               name = 'classifier')\n",
    "        \n",
    "    def call(self, inputs, attention_mask = None, token_type_ids = None, training = False):\n",
    "        outputs = self.bert(inputs, attention_mask = attention_mask, token_type_ids = token_type_ids)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output, training = training)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "cls_model = TFBertClassifier(model_name = 'bert-base-multilingual-cased',\n",
    "                            dir_path = 'bert_ckpt',\n",
    "                            num_class=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa47b3f0-f612-4989-950c-d8a0d69bd5cc",
   "metadata": {},
   "source": [
    "<b>모델 학습</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bedb9c3b-2ebd-4153-be06-4f2345c28192",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer  = tf.keras.optimizers.Adam(3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "cls_model.compile(optimizer = optimizer, loss = loss, metrics = [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1fb75-e403-4b81-bba9-2a3c2201ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'tf2_bert_naver_movie'\n",
    "\n",
    "es_callback = EarlyStopping(monitor = 'val_accuracy', min_delta = 0.0001, patience = 2)\n",
    "\n",
    "checkpoint_path = os.path.join('./', model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} Directory already exists\\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok = True)\n",
    "    print(\"{} Directory already exists\\n\".format(checkpoint_dir))\n",
    "\n",
    "cp_callback = ModelCheckpoint(checkpoint_path, monitor = 'val_accuracy',\n",
    "                             verbose = 1, save_best_only = True, save_weights_only = True)\n",
    "\n",
    "history = cls_model.fit(train_movie_inputs, train_data_labels,\n",
    "                       epochs = NUM_EPOCHS, batch_size = BATCH_SIZE, validation_split = VALID_SPLIT,\n",
    "                       callbacks = [es_callback, cp_callback])\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada554d-26d6-423c-ac7c-0e973da6728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_losss'], '')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092365a4-754e-420a-9472-13609785eee4",
   "metadata": {},
   "source": [
    "<b>모델 평가</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d3812f-a25a-4f15-80a9-47db9fdfbdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "test_data_labels = []\n",
    "\n",
    "for test_sentence, test_label in tqdm(zip(test_data['document'], test_data['label'])):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(test_sentence, MAX_LEN)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        test_data_labels.append(test_label)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "test_movie_input_ids = np.array(input_ids , dtype = int)\n",
    "test_movie_attention_masks = np.array(attention_masks, dtype = int)\n",
    "test_movie_token_type_ids = np.array(token_type_ids, dtype = int)\n",
    "test_movie_inputs = (test_movie_input_ids, test_movie_attention_masks, test_movie_token_type_ids)\n",
    "test_data_labels = np.asarray(test_data_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad41611-5212-45f1-a0c5-cd0457b0bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model.evaluate(test_movie_inputs, test_data_labels, batch_size = 1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
